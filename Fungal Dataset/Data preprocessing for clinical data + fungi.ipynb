{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the clinical data\n",
    "df1 = pd.read_excel('1_Clinical data AH_AUD_HC Bernd_bei_updated08012019.xlsx')\n",
    "df = df1[['subject_id',\n",
    "          'age', 'alt', 'ast', 'creatinine_value_mg_dl',\n",
    "          'bilirubin_value_mg_dl', 'platelets_value_10to9_l', 'wbc_10to9_l', 'alk_phos',\n",
    "          'albumin_value_g_dl', 'sodium', 'inr', 'dialysis_required',\n",
    "          'ThirtyMo', 'NinetyMo']]\n",
    "\n",
    "df_30 = df[pd.notnull(df['ThirtyMo'])].drop(['NinetyMo'], axis = 1)\n",
    "df_90 = df[pd.notnull(df['NinetyMo'])].drop(['ThirtyMo'], axis = 1)\n",
    "\n",
    "# Fill dialysis\n",
    "df_30.fillna({'dialysis_required': 0}, inplace = True)\n",
    "df_90.fillna({'dialysis_required': 0}, inplace = True)\n",
    "\n",
    "# Calculate MELD score (2016) before imputation\n",
    "df_30['MELD'] = df_30.apply(lambda row:\n",
    "                            9.57 * np.log(np.where(row.dialysis_required == 0,\n",
    "                                                   np.minimum(np.maximum(row.creatinine_value_mg_dl, 1.0), 4.0),\n",
    "                                                   4)) +\n",
    "                            3.78 * np.log(np.maximum(row.bilirubin_value_mg_dl, 1.0)) +\n",
    "                            11.2 * np.log(np.maximum(row.inr, 1.0)) +\n",
    "                            6.43,\n",
    "                            axis = 1)\n",
    "df_30['MELD_2016'] = df_30.apply(lambda row:\n",
    "                                 np.where(row.MELD > 11,\n",
    "                                          row.MELD +\n",
    "                                          1.32 * (137 - np.minimum(np.maximum(row.sodium, 125), 137)) -\n",
    "                                          0.033 * row.MELD * (137 - np.minimum(np.maximum(row.sodium, 125), 137)),\n",
    "                                          row.MELD),\n",
    "                                 axis = 1)\n",
    "\n",
    "df_90['MELD'] = df_90.apply(lambda row:\n",
    "                            9.57 * np.log(np.where(row.dialysis_required == 0,\n",
    "                                                   np.minimum(np.maximum(row.creatinine_value_mg_dl, 1.0), 4.0),\n",
    "                                                   4)) +\n",
    "                            3.78 * np.log(np.maximum(row.bilirubin_value_mg_dl, 1.0)) +\n",
    "                            11.2 * np.log(np.maximum(row.inr, 1.0)) +\n",
    "                            6.43,\n",
    "                            axis = 1)\n",
    "df_90['MELD_2016'] = df_90.apply(lambda row:\n",
    "                                 np.where(row.MELD > 11,\n",
    "                                          row.MELD +\n",
    "                                          1.32 * (137 - np.minimum(np.maximum(row.sodium, 125), 137)) -\n",
    "                                          0.033 * row.MELD * (137 - np.minimum(np.maximum(row.sodium, 125), 137)),\n",
    "                                          row.MELD),\n",
    "                                 axis = 1)\n",
    "\n",
    "df_30 = df_30.drop(['dialysis_required'], axis = 1)\n",
    "df_90 = df_90.drop(['dialysis_required'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read fungi data and merge it with clinical data\n",
    "df2 = pd.read_excel('2_Fungi - updated on 03312020.xlsx')\n",
    "na_removing_list2 = list(df2.columns)\n",
    "na_removing_list2.pop(0)\n",
    "\n",
    "df_30 = df_30.merge(df2, how = 'left', on = 'subject_id')\n",
    "df_90 = df_90.merge(df2, how = 'left', on = 'subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Observations missing rate\n",
    "print(np.round(1 - df_30.dropna().shape[0] / df_30.shape[0], decimals = 2))\n",
    "print(np.round(1 - df_90.dropna().shape[0] / df_90.shape[0], decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations missing with all fungi data\n",
    "df_30 = df_30.dropna(how = 'all', subset = na_removing_list2)\n",
    "df_90 = df_90.dropna(how = 'all', subset = na_removing_list2)\n",
    "\n",
    "# Export the data with MELD score (2016)\n",
    "df_30.to_csv('MELD2_30.csv', index = False)\n",
    "df_90.to_csv('MELD2_90.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 96)\n",
      "(39, 96)\n"
     ]
    }
   ],
   "source": [
    "print(df_30.shape)\n",
    "print(df_90.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 96)\n",
      "(32, 96)\n"
     ]
    }
   ],
   "source": [
    "print(df_30.dropna().shape)\n",
    "print(df_90.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "0.18\n"
     ]
    }
   ],
   "source": [
    "# Observations missing rate\n",
    "print(np.round(1 - df_30.dropna().shape[0] / df_30.shape[0], decimals = 2))\n",
    "print(np.round(1 - df_90.dropna().shape[0] / df_90.shape[0], decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating feature matrix\n",
    "X_30 = df_30.drop(['subject_id', 'ThirtyMo'] , axis = 1)\n",
    "X_90 = df_90.drop(['subject_id', 'NinetyMo'] , axis = 1)\n",
    "\n",
    "# Creating labels\n",
    "y_30 = df_30['ThirtyMo']\n",
    "y_90 = df_90['NinetyMo']\n",
    "\n",
    "# Saving feature names for later use\n",
    "X_list_30_raw = list(X_30.columns)\n",
    "X_list_90_raw = list(X_90.columns)\n",
    "X_list_30 = [i for i in X_list_30_raw if i not in ('MELD', 'MELD_2016')]\n",
    "X_list_90 = [i for i in X_list_90_raw if i not in ('MELD', 'MELD_2016')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    49\n",
      "1     5\n",
      "Name: ThirtyMo, dtype: int64\n",
      "0.0    30\n",
      "1.0     9\n",
      "Name: NinetyMo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check whether data is balanced\n",
    "print(y_30.value_counts())\n",
    "print(y_90.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For died within 30 days outcome\n",
    "\n",
    "# Stratified 5-fold split\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "skf.get_n_splits(X_30, y_30)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(X_30, y_30):\n",
    "    X_train_30, y_train_30 = X_30.iloc[train_index], y_30.iloc[train_index]\n",
    "    X_test_30, y_test_30 = X_30.iloc[test_index], y_30.iloc[test_index]\n",
    "    \n",
    "    # Export the raw training data\n",
    "    train_30 = pd.DataFrame(np.column_stack([X_train_30, y_train_30]))\n",
    "    train_30.columns = np.concatenate((X_list_30_raw, 'ThirtyMo'), axis = None)\n",
    "    test_30 = pd.DataFrame(np.column_stack([X_test_30, y_test_30]))\n",
    "    test_30.columns = np.concatenate((X_list_30_raw, 'ThirtyMo'), axis = None)\n",
    "    \n",
    "    train_30.to_csv('train2_30_raw' + str(i) + '.csv', index = False)\n",
    "    test_30.to_csv('test2_30_raw' + str(i) + '.csv', index = False)\n",
    "    \n",
    "    X_train_30 = X_train_30.drop(['MELD', 'MELD_2016'], axis = 1)\n",
    "    X_test_30 = X_test_30.drop(['MELD', 'MELD_2016'], axis = 1)\n",
    "    \n",
    "    # Apply MICE imputation to training data and use the same imputation model to test data\n",
    "    MICE_imputer = IterativeImputer(sample_posterior = True, min_value = 0, random_state = 0)\n",
    "    X_train_30_imp = MICE_imputer.fit_transform(X_train_30)\n",
    "    X_test_30_imp = MICE_imputer.transform(X_test_30)\n",
    "    \n",
    "    # Export the training data and test data\n",
    "    train_30 = pd.DataFrame(np.column_stack([X_train_30_imp, y_train_30]))\n",
    "    train_30.columns = np.concatenate((X_list_30, 'ThirtyMo'), axis = None)\n",
    "    test_30 = pd.DataFrame(np.column_stack([X_test_30_imp, y_test_30]))\n",
    "    test_30.columns = np.concatenate((X_list_30, 'ThirtyMo'), axis = None)\n",
    "    \n",
    "    train_30.to_csv('train2_30_imp' + str(i) + '.csv', index = False)\n",
    "    test_30.to_csv('test2_30_imp' + str(i) + '.csv', index = False)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For died within 90 days outcome\n",
    "\n",
    "# Stratified 5-fold split\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "skf.get_n_splits(X_90, y_90)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(X_90, y_90):\n",
    "    X_train_90, y_train_90 = X_90.iloc[train_index], y_90.iloc[train_index]\n",
    "    X_test_90, y_test_90 = X_90.iloc[test_index], y_90.iloc[test_index]\n",
    "    \n",
    "    # Export the raw training data\n",
    "    train_90 = pd.DataFrame(np.column_stack([X_train_90, y_train_90]))\n",
    "    train_90.columns = np.concatenate((X_list_90_raw, 'NinetyMo'), axis = None)\n",
    "    test_90 = pd.DataFrame(np.column_stack([X_test_90, y_test_90]))\n",
    "    test_90.columns = np.concatenate((X_list_90_raw, 'NinetyMo'), axis = None)\n",
    "    \n",
    "    train_90.to_csv('train2_90_raw' + str(i) + '.csv', index = False)\n",
    "    test_90.to_csv('test2_90_raw' + str(i) + '.csv', index = False)\n",
    "    \n",
    "    X_train_90 = X_train_90.drop(['MELD', 'MELD_2016'], axis = 1)\n",
    "    X_test_90 = X_test_90.drop(['MELD', 'MELD_2016'], axis = 1)\n",
    "    \n",
    "    # Apply MICE imputation to training data and use the same imputation model to test data\n",
    "    MICE_imputer = IterativeImputer(sample_posterior = True, min_value = 0, random_state = 0)\n",
    "    X_train_90_imp = MICE_imputer.fit_transform(X_train_90)\n",
    "    X_test_90_imp = MICE_imputer.transform(X_test_90)\n",
    "    \n",
    "    # Export the training data and test data\n",
    "    train_90 = pd.DataFrame(np.column_stack([X_train_90_imp, y_train_90]))\n",
    "    train_90.columns = np.concatenate((X_list_90, 'NinetyMo'), axis = None)\n",
    "    test_90 = pd.DataFrame(np.column_stack([X_test_90_imp, y_test_90]))\n",
    "    test_90.columns = np.concatenate((X_list_90, 'NinetyMo'), axis = None)\n",
    "    \n",
    "    train_90.to_csv('train2_90_imp' + str(i) + '.csv', index = False)\n",
    "    test_90.to_csv('test2_90_imp' + str(i) + '.csv', index = False)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For died within 30 days outcome\n",
    "\n",
    "for i in range(5):\n",
    "    # Import the training data after feature selection\n",
    "    train_30_sel = pd.read_csv('train2_30_sel' + str(i) + '.csv')\n",
    "    X_train_30_sel = train_30_sel.drop('ThirtyMo', axis = 1)\n",
    "    y_train_30 = train_30_sel['ThirtyMo']\n",
    "    X_sel_list_30 = list(X_train_30_sel.columns)\n",
    "    \n",
    "    # Use SMOTE to over sample the minority class for training data\n",
    "    sm = SMOTE(random_state = 0, k_neighbors = 3)\n",
    "    X_train_30_res, y_train_30_res = sm.fit_resample(X_train_30_sel, y_train_30)\n",
    "    \n",
    "    train_30 = pd.DataFrame(np.column_stack([X_train_30_res, y_train_30_res]))\n",
    "    train_30.columns = np.concatenate((X_sel_list_30, 'ThirtyMo'), axis = None)\n",
    "    \n",
    "    train_30.to_csv('train2_30_' + str(i) + '.csv', index = False)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For died within 90 days outcome\n",
    "\n",
    "for i in range(5):\n",
    "    # Import the training data after feature selection\n",
    "    train_90_sel = pd.read_csv('train2_90_sel' + str(i) + '.csv')\n",
    "    X_train_90_sel = train_90_sel.drop('NinetyMo', axis = 1)\n",
    "    y_train_90 = train_90_sel['NinetyMo']\n",
    "    X_sel_list_90 = list(X_train_90_sel.columns)\n",
    "    \n",
    "    # Use SMOTE to over sample the minority class for training data\n",
    "    sm = SMOTE(random_state = 0, k_neighbors = 3)\n",
    "    X_train_90_res, y_train_90_res = sm.fit_resample(X_train_90_sel, y_train_90)\n",
    "    \n",
    "    train_90 = pd.DataFrame(np.column_stack([X_train_90_res, y_train_90_res]))\n",
    "    train_90.columns = np.concatenate((X_sel_list_90, 'NinetyMo'), axis = None)\n",
    "    \n",
    "    train_90.to_csv('train2_90_' + str(i) + '.csv', index = False)\n",
    "    \n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
